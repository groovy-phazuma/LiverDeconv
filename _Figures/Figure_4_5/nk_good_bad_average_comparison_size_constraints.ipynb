{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of average estimated score about good and bad combinations with size constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% GSE111818 optimization\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:/github/LiverDeconv')\n",
    "import liver_deconv as ld\n",
    "from _utils import processing as pc\n",
    "from _utils import plot4deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_dir = 'C:/github/LiverDeconv' # cloning repository\n",
    "# load data\n",
    "mix_df = pd.read_csv('C:/github/LiverDeconv/_Figures_new/Figure_5/data/gse111828_exp_matrix.csv',index_col=0)\n",
    "ref = pd.read_csv(Base_dir + '/data/processed/ref_13types.csv',index_col=0)\n",
    "\n",
    "comb_df = pd.read_pickle('C:/github/LiverDeconv/_Figures_new/Figure_4/data/nk_fluctuate_quartile_comb2ref.pkl')\n",
    "comb_df = comb_df.sort_values(\"NK\",ascending=False)\n",
    "comb = comb_df['pair'].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "##### Good combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12076, 24)\n",
      "(51463, 70)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 450\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 450\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 60)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 400\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 400\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 69)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 400\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 400\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 89)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 533\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 533\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 81)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12037\n",
      "signature genes : 450\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 450\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 72)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 450\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 450\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 74)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 450\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 450\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 82)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 500\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 500\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 86)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 500\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 500\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 77)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 500\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 500\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n"
     ]
    }
   ],
   "source": [
    "#%% good mean vs bad mean\n",
    "n = 10\n",
    "# good\n",
    "good_summary = pd.DataFrame()\n",
    "good_size = []\n",
    "for i in range(n):\n",
    "    use_cell = ['NK']\n",
    "    target_cells = copy.deepcopy(use_cell)\n",
    "    #target_cells.extend([t.split(\"'\")[0] for t in comb[i][2:-2].split(\"', '\")])\n",
    "    target_cells.extend(list(comb[i]))\n",
    "    good_size.append(len(target_cells))\n",
    "    # select use sample\n",
    "    use_sample = []\n",
    "    for t in ref.columns.tolist():\n",
    "        if t.split(\"_\")[0] in target_cells:\n",
    "            use_sample.append(t)\n",
    "    use_ref = ref[use_sample]\n",
    "    \n",
    "    # define reference\n",
    "    dat = ld.LiverDeconv()\n",
    "    dat.set_data(df_mix=mix_df,df_all=use_ref)\n",
    "    dat.pre_processing(do_ann=False,ann_df=None,do_log2=True,do_quantile=True,do_trimming=False,do_drop=True)\n",
    "    dat.narrow_intersec()\n",
    "    dat.create_ref(sep=\"_\",number=50,limit_CV=10,limit_FC=1.5,log2=False,verbose=False)\n",
    "    \n",
    "    df_mix = dat.df_mix\n",
    "    df_all = dat.df_all\n",
    "    \n",
    "    final_ref = dat.final_ref\n",
    "    \n",
    "    dat.do_fit(file_dat=mix_df,file_ref=final_ref,max_iter=1e6,number_of_repeats=3,alpha=1,l1_ratio=0.05)\n",
    "    res = dat.get_res()\n",
    "    z_good = pc.standardz_sample(res)\n",
    "    z_good.index = [i.split(\" \")[0] for i in z_good.index]\n",
    "    ctrl_mean = z_good.loc[\"0hr\"][\"NK\"].mean()\n",
    "    fxn = lambda x : x-ctrl_mean\n",
    "    z_good['NK'] = z_good['NK'].apply(fxn)\n",
    "    good_summary[i] = z_good['NK']\n",
    "\n",
    "good_summary['name'] = good_summary.index.tolist()\n",
    "good_melt = pd.melt(good_summary.groupby('name').mean().T)\n",
    "good_melt['status']=['good']*len(good_melt)\n",
    "good_melt.columns = ['variable','value','status']\n",
    "\n",
    "good_min = min(good_size)\n",
    "\n",
    "# save\n",
    "good_melt.to_csv('C:/github/LiverDeconv/_Figures_new/Figure_5/results/nk_good_melt.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "##### Bad combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12076, 24)\n",
      "(51463, 70)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 450\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 450\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 75)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 352\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 352\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 73)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 450\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 450\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 72)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 369\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 369\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 81)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 351\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 351\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 78)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 351\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 351\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 77)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 355\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 355\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 77)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 353\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 353\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 75)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 350\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 350\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n",
      "(12076, 24)\n",
      "(51463, 84)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 367\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 367\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# bad\n",
    "bad_summary = pd.DataFrame()\n",
    "c = 0\n",
    "bad_size = []\n",
    "for i in range(3000):\n",
    "    if c == n:\n",
    "        break\n",
    "    use_cell = ['NK']\n",
    "    target_cells = copy.deepcopy(use_cell)\n",
    "    #target_cells.extend([t.split(\"'\")[0] for t in comb[-i][2:-2].split(\"', '\")]) # -i th\n",
    "    target_cells.extend(list(comb[-i]))\n",
    "    if len(target_cells)<good_min:\n",
    "        # skip if the target cell combination size is maller than good one\n",
    "        continue\n",
    "    bad_size.append(len(target_cells))\n",
    "    # select use sample\n",
    "    use_sample = []\n",
    "    for t in ref.columns.tolist():\n",
    "        if t.split(\"_\")[0] in target_cells:\n",
    "            use_sample.append(t)\n",
    "    use_ref = ref[use_sample]\n",
    "    \n",
    "    # define reference\n",
    "    dat = ld.LiverDeconv()\n",
    "    dat.set_data(df_mix=mix_df,df_all=use_ref)\n",
    "    dat.pre_processing(do_ann=False,ann_df=None,do_log2=True,do_quantile=True,do_trimming=False,do_drop=True)\n",
    "    dat.narrow_intersec()\n",
    "    dat.create_ref(sep=\"_\",number=50,limit_CV=10,limit_FC=1.5,log2=False,verbose=False)\n",
    "    \n",
    "    df_mix = dat.df_mix\n",
    "    df_all = dat.df_all\n",
    "    \n",
    "    final_ref = dat.final_ref\n",
    "    \n",
    "    dat.do_fit(file_dat=mix_df,file_ref=final_ref,max_iter=1e6,number_of_repeats=3,alpha=1,l1_ratio=0.05)\n",
    "    res = dat.get_res()\n",
    "    z_bad = pc.standardz_sample(res)\n",
    "    z_bad.index = [i.split(\" \")[0] for i in z_bad.index]\n",
    "    ctrl_mean = z_bad.loc[\"0hr\"][\"NK\"].mean()\n",
    "    fxn = lambda x : x-ctrl_mean\n",
    "    z_bad['NK'] = z_bad['NK'].apply(fxn)\n",
    "    bad_summary[i] = z_bad['NK']\n",
    "    c += 1\n",
    "bad_summary['name'] = bad_summary.index.tolist()\n",
    "bad_melt = pd.melt(bad_summary.groupby('name').mean().T)\n",
    "bad_melt['status']=['bad']*len(bad_melt)\n",
    "bad_melt.columns = ['variable','value','status']\n",
    "\n",
    "# save\n",
    "bad_melt.to_csv('C:/github/LiverDeconv/_Figures_new/Figure_5/results/nk_bad_melt.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "##### Baseline (13 cell types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12076, 24)\n",
      "(51463, 113)\n",
      "log2 conversion\n",
      "quantile normalization\n",
      "drop nan\n",
      "narrowd gene number : 12039\n",
      "signature genes : 521\n",
      "0 rows are removed\n",
      "0 rows are removed\n",
      "number of used genes = 521\n",
      "fitting method : ElasticNet\n",
      "standardz population control\n"
     ]
    }
   ],
   "source": [
    "target_cells = ['B','Basophil','CD4','CD8','Cholangiocyte','Eosinophil','Hepatocyte','Kupffer','LSEC','Monocyte','NK','Neutrophil','Stellate']\n",
    "# select use sample\n",
    "use_sample = []\n",
    "for t in ref.columns.tolist():\n",
    "    if t.split(\"_\")[0] in target_cells:\n",
    "        use_sample.append(t)\n",
    "use_ref = ref[use_sample]\n",
    "\n",
    "# define reference\n",
    "dat = ld.LiverDeconv()\n",
    "dat.set_data(df_mix=mix_df,df_all=use_ref)\n",
    "dat.pre_processing(do_ann=False,ann_df=None,do_log2=True,do_quantile=True,do_trimming=False,do_drop=True)\n",
    "dat.narrow_intersec()\n",
    "dat.create_ref(sep=\"_\",number=50,limit_CV=10,limit_FC=1.5,log2=False,verbose=False)\n",
    "\n",
    "df_mix = dat.df_mix\n",
    "df_all = dat.df_all\n",
    "\n",
    "final_ref = dat.final_ref\n",
    "\n",
    "dat.do_fit(file_dat=mix_df,file_ref=final_ref,max_iter=1e6,number_of_repeats=3,alpha=1,l1_ratio=0.05)\n",
    "res = dat.get_res()\n",
    "z_total = pc.standardz_sample(res)\n",
    "z_total.index = [i.split(\" \")[0] for i in z_total.index]\n",
    "ctrl_mean = z_total.loc[\"0hr\"][\"NK\"].mean()\n",
    "fxn = lambda x : x-ctrl_mean\n",
    "z_total['NK'] = z_total['NK'].apply(fxn)\n",
    "\n",
    "total_summary = pd.DataFrame()\n",
    "total_summary[0] = z_total['NK']\n",
    "\n",
    "total_summary['name'] = total_summary.index.tolist()\n",
    "total_melt = pd.melt(total_summary.groupby('name').mean().T)\n",
    "total_melt['status']=['total']*len(total_melt)\n",
    "total_melt.columns = ['variable','value','status']\n",
    "\n",
    "total_melt.to_csv('C:/github/LiverDeconv/_Figures_new/Figure_5/results/nk_baseline_melt.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piphazuma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf1ec4ce3386f079608efef299d25012785f638f09c8399df9141df8012c0806"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
